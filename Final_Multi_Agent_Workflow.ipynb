{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KZx7xN5uI1qo",
        "outputId": "4e7039b2-6132-42ba-c3cf-9a255564dff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.28)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.72.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.13.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.72.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: langchain-experimental in /usr/local/lib/python3.11/dist-packages (0.3.4)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain-experimental) (0.3.21)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.28 in /usr/local/lib/python3.11/dist-packages (from langchain-experimental) (0.3.52)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.8.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.28)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.2.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.28->langchain-experimental) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.28->langchain-experimental) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.28->langchain-experimental) (4.13.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.28->langchain-experimental) (2.11.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.19.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.28->langchain-experimental) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.8)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.28->langchain-experimental) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.28->langchain-experimental) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.28->langchain-experimental) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.3.1)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (0.3.52)\n",
            "Requirement already satisfied: langchain-anthropic in /usr/local/lib/python3.11/dist-packages (0.3.11)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.3.30)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (0.3.28)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (4.13.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (2.11.3)\n",
            "Requirement already satisfied: anthropic<1,>=0.49.0 in /usr/local/lib/python3.11/dist-packages (from langchain-anthropic) (0.49.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.24)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.8)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.61)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.16)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (0.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.49.0->langchain-anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.49.0->langchain-anthropic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.49.0->langchain-anthropic) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<1,>=0.49.0->langchain-anthropic) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (2.3.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-openai pandas\n",
        "!pip install openai\n",
        "!pip install nest-asyncio\n",
        "!pip install langchain-experimental\n",
        "!pip install langchain_core langchain-anthropic langgraph\n",
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-7u44jWkS4S",
        "outputId": "1578f376-3762-444c-e1ad-72b2554bce63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: uv in /usr/local/lib/python3.11/dist-packages (0.6.14)\n"
          ]
        }
      ],
      "source": [
        "# Install package first\n",
        "# We use uv for faster installation\n",
        "\n",
        "# Google Colab is setting some uv-related environment variables, that seem to have broken with the a Colab update.\n",
        "# The Colab team is tracking this internally (googlecolab/colabtools#5237).\n",
        "# https://github.com/googlecolab/colabtools/issues/5237#issuecomment-2786440777\n",
        "import os\n",
        "os.environ[\"UV_CONSTRAINT\"] = os.environ[\"UV_BUILD_CONSTRAINT\"] = \"\"  # add this line to solve the uv related issue\n",
        "\n",
        "!pip install uv\n",
        "!uv pip install -q autogluon.timeseries --system --prerelease allow\n",
        "!uv pip uninstall -q torchaudio torchvision torchtext --system # fix incompatible package versions on Colab\n",
        "\n",
        "\n",
        "## if there seems to be inconsistency due to numpy & pandas versions, do the following\n",
        "# !uv pip uninstall pandas numpy\n",
        "!uv pip install -q --force-reinstall numpy==1.26.4 --system --prerelease allow\n",
        "!uv pip install -q --force-reinstall pandas==2.2.2 --system --prerelease allow\n",
        "## You may need to restart colab kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdC8DyN2k_OQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8qmYy_OpNE4v",
        "outputId": "fc7d4620-f865-4654-be3b-8493ac67b20a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.51)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.70.0)\n",
            "Collecting openai\n",
            "  Downloading openai-1.73.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.24)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.13.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Downloading openai-1.73.0-py3-none-any.whl (644 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.4/644.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.70.0\n",
            "    Uninstalling openai-1.70.0:\n",
            "      Successfully uninstalled openai-1.70.0\n",
            "Successfully installed openai-1.73.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install --upgrade langchain langchain-core langchain-openai openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDVfecisJGxj"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
        "from langchain_openai import OpenAI, ChatOpenAI\n",
        "import nest_asyncio\n",
        "import pandas as pd\n",
        "\n",
        "from typing_extensions import Literal\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langgraph.func import entrypoint, task\n",
        "\n",
        "import re\n",
        "from langchain.docstore.document import Document\n",
        "import faiss\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_aun4FZZ4I8",
        "outputId": "e388a09e-5330-41af-96a0-c6d49f480e03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm3Zz-rfZ8Kv",
        "outputId": "35f332e4-5630-4b76-c9d0-5000ada56e4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/GE_Capstone/AI Agent Workflow\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/GE_Capstone/AI Agent Workflow/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hePSndWwhVmJ"
      },
      "source": [
        "### Workflow to Handle Multiple Tasks in One Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "VAOyMBD3JBqq",
        "outputId": "6f973571-c11c-4344-c437-9f65876e164d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d3eee801-8722-4a0c-b39e-d923a634252e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d3eee801-8722-4a0c-b39e-d923a634252e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 144,\n  \"fields\": [\n    {\n      \"column\": \"item_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 144,\n        \"samples\": [\n          \"1958-10-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 119,\n        \"min\": 104,\n        \"max\": 622,\n        \"num_unique_values\": 118,\n        \"samples\": [\n          293\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2765dcb8-60a2-420b-81d6-b445e3308715\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1949-01-01 00:00:00</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1949-02-01 00:00:00</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1949-03-01 00:00:00</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1949-04-01 00:00:00</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1949-05-01 00:00:00</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2765dcb8-60a2-420b-81d6-b445e3308715')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2765dcb8-60a2-420b-81d6-b445e3308715 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2765dcb8-60a2-420b-81d6-b445e3308715');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1071499a-318b-4d93-ba32-e6118e827346\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1071499a-318b-4d93-ba32-e6118e827346')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1071499a-318b-4d93-ba32-e6118e827346 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   item_id            timestamp  target\n",
              "0        1  1949-01-01 00:00:00     112\n",
              "1        1  1949-02-01 00:00:00     118\n",
              "2        1  1949-03-01 00:00:00     132\n",
              "3        1  1949-04-01 00:00:00     129\n",
              "4        1  1949-05-01 00:00:00     121"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "# df = pd.read_csv(\"subset.csv\")  # Replace with your actual filename\n",
        "df = pd.read_csv(\"reform_AirPassengersDataset_DARTS_144.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRFxduNTImmS",
        "outputId": "e94d7981-3965-4e16-d513-736ddc6b64b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-346f1f8b5590>:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n"
          ]
        }
      ],
      "source": [
        "# df = df.drop('Slope', axis=1)\n",
        "# df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
        "# df[\"timestamp\"] = (df[\"datetime\"] - df[\"datetime\"].min()).dt.total_seconds()/3600"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7HeDo6GtvVI"
      },
      "outputs": [],
      "source": [
        "llm_4 = ChatOpenAI(\n",
        "\tapi_key=\"replace with your api\",\n",
        "    model_name=\"gpt-4\",\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "llm_turbo = ChatOpenAI(\n",
        "\tapi_key=\"replace with your api\",\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0.7\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQpWabTevV4P"
      },
      "outputs": [],
      "source": [
        "agent_threshold = create_pandas_dataframe_agent(llm_turbo, df, verbose=True, allow_dangerous_code=True)\n",
        "agent_slope = create_pandas_dataframe_agent(llm_4, df, verbose=True, allow_dangerous_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_SemHL1vF-9",
        "outputId": "cc77df9e-9d09-4e40-9de6-5d1dde18f344"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1637: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "## route user input to the correct agent\n",
        "class Route(BaseModel):\n",
        "    step: Literal[\"slope\", \"exceedance\", \"separate\"] = Field(\n",
        "        None, description=\"The next step in the routing process\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Augment the LLM with schema for structured output\n",
        "router = llm_4.with_structured_output(Route)\n",
        "\n",
        "\n",
        "@task\n",
        "def llm_call_1(input_: str):\n",
        "    \"\"\"Slope Calculation\"\"\"\n",
        "    result = agent_slope.invoke(input_)\n",
        "    return result\n",
        "\n",
        "\n",
        "@task\n",
        "def llm_call_2(input_: str):\n",
        "    \"\"\"Threshold Exceedance\"\"\"\n",
        "    result = agent_threshold.invoke(input_)\n",
        "    return result\n",
        "\n",
        "@task\n",
        "def llm_call_3(input_: str):\n",
        "    \"\"\"Split Prompt\"\"\"\n",
        "    result = llm_4.invoke(input_)\n",
        "    prompts = result.content.splitlines()\n",
        "    all_results = []\n",
        "    for prompt in prompts:\n",
        "      if prompt == \"\":\n",
        "        continue\n",
        "      print(f\"Sub-prompt: {prompt}\")\n",
        "      for step in router_workflow_2.stream(prompt, stream_mode=\"updates\"):\n",
        "        all_results.append(step)\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "def llm_call_router(input_: str):\n",
        "    \"\"\"Route the input to the appropriate node\"\"\"\n",
        "    decision = router.invoke(\n",
        "        [\n",
        "            SystemMessage(\n",
        "                content=\"Route the input to slope, threshold, or separate based on the user's request.\"\n",
        "            ),\n",
        "            HumanMessage(content=input_),\n",
        "        ]\n",
        "    )\n",
        "    return decision.step\n",
        "\n",
        "\n",
        "# Create workflow\n",
        "@entrypoint()\n",
        "def router_workflow_1(input_: str):\n",
        "    next_step = llm_call_router(input_)\n",
        "    if next_step == \"slope\":\n",
        "        llm_call = llm_call_1\n",
        "    elif next_step == \"exceedance\":\n",
        "        llm_call = llm_call_2\n",
        "    elif next_step == \"separate\":\n",
        "        llm_call = llm_call_3\n",
        "\n",
        "    return  llm_call(input_).result()\n",
        "\n",
        "@entrypoint()\n",
        "def router_workflow_2(input_: str):\n",
        "    next_step = llm_call_router(input_)\n",
        "    if next_step == \"slope\":\n",
        "        llm_call = llm_call_1\n",
        "    elif next_step == \"exceedance\":\n",
        "        llm_call = llm_call_2\n",
        "    elif next_step == \"separate\":\n",
        "        llm_call = llm_call_3\n",
        "\n",
        "    return {\n",
        "        llm_call.__name__: {\n",
        "            \"result\": llm_call(input_).result()\n",
        "        }\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vk_lpvwDwDBm",
        "outputId": "6fca1fdb-285c-4a45-fe5c-7d4c548a8bf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sub-prompt: 1. What is the slope of values in the target column of df. Only return slope of target column, no explanation.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To find the slope of the values in the target column, we first need to turn the 'target' column into a list or array. After that, we can use the numpy's polyfit function to find the slope and the intercept of the line that best fits the data. The first value returned by the function is the slope and the second value is the intercept.\n",
            "Action: python_repl_ast\n",
            "Action Input: \n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "x = df.index\n",
            "y = df['target']\n",
            "\n",
            "slope, intercept = np.polyfit(x, y, 1)\n",
            "slope\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3m2.657183908045976\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: The slope of the values in the target column of df is 2.657183908045976.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Sub-prompt: 2. Calculate the 95% for target column of df. Only return a list of numbers that exceed the 95% value, no explanation.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To calculate the 95th percentile of the 'target' column in the dataframe, and then filter out values that exceed this percentile.\n",
            "Action: python_repl_ast\n",
            "Action Input: df['target'].quantile(0.95)\u001b[0m\u001b[36;1m\u001b[1;3m488.14999999999986\u001b[0m\u001b[32;1m\u001b[1;3mNow I need to filter out values in the 'target' column that exceed the 95th percentile value.\n",
            "Action: python_repl_ast\n",
            "Action Input: df[df['target'] > df['target'].quantile(0.95)]['target'].tolist()\u001b[0m\u001b[36;1m\u001b[1;3m[491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: [491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'llm_call_3': [{'llm_call_1': {'result': {'input': '1. What is the slope of values in the target column of df. Only return slope of target column, no explanation.', 'output': 'The slope of the values in the target column of df is 2.657183908045976.'}}}, {'llm_call_2': {'result': {'input': '2. Calculate the 95% for target column of df. Only return a list of numbers that exceed the 95% value, no explanation.', 'output': '[491, 505, 548, 559, 535, 622, 606, 508]'}}}]}\n",
            "\n",
            "\n",
            "{'router_workflow_1': [{'llm_call_1': {'result': {'input': '1. What is the slope of values in the target column of df. Only return slope of target column, no explanation.', 'output': 'The slope of the values in the target column of df is 2.657183908045976.'}}}, {'llm_call_2': {'result': {'input': '2. Calculate the 95% for target column of df. Only return a list of numbers that exceed the 95% value, no explanation.', 'output': '[491, 505, 548, 559, 535, 622, 606, 508]'}}}]}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for step in router_workflow_1.stream(\"Two prompts are in this sentence. Please separate and return them. What is the slope of values in the target column of df. Only return slope of target column, no explanation. Calculate the 95% for target column of df. Only return a list of numbers that exceed the 95% value, no explanation.\", stream_mode=\"updates\"):\n",
        "    print(step)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEaU74UZb3NG",
        "outputId": "5ab2c517-bfa9-4089-b609-e7fd8cd8d252"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sub-prompt: 1) What is the slope of values in the target column of df. Only return slope of target column, no explanation.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To find the slope of the values in the target column, we need to perform a linear regression on the index of the dataframe and the target column. The slope of the regression line will give us the slope of the values in the target column. We can use the `linregress` function from the `scipy.stats` module to perform the linear regression.\n",
            "\n",
            "Action: python_repl_ast\n",
            "Action Input: \n",
            "```python\n",
            "from scipy.stats import linregress\n",
            "\n",
            "# Get the index values and target column values as lists\n",
            "x = df.index.tolist()\n",
            "y = df['target'].tolist()\n",
            "\n",
            "# Perform linear regression and get the slope\n",
            "slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
            "slope\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3m2.657183908045977\u001b[0m\u001b[32;1m\u001b[1;3mThe slope of the values in the target column of the dataframe is approximately 2.657.\n",
            "Final Answer: 2.657\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Sub-prompt: 2) Calculate the 95% for target column of df. Only return a list of numbers that exceed the 95% value, no explanation.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To calculate the 95th percentile value for the 'target' column in the dataframe, and then filter out values greater than that.\n",
            "Action: python_repl_ast\n",
            "Action Input: df['target'].quantile(0.95)\u001b[0m\u001b[36;1m\u001b[1;3m488.14999999999986\u001b[0m\u001b[32;1m\u001b[1;3mNow, filter out values in the 'target' column that exceed the 95th percentile value.\n",
            "Action: python_repl_ast\n",
            "Action Input: df[df['target'] > df['target'].quantile(0.95)]['target'].tolist()\u001b[0m\u001b[36;1m\u001b[1;3m[491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: [491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'llm_call_3': [{'llm_call_1': {'result': {'input': '1) What is the slope of values in the target column of df. Only return slope of target column, no explanation.', 'output': '2.657'}}}, {'llm_call_2': {'result': {'input': '2) Calculate the 95% for target column of df. Only return a list of numbers that exceed the 95% value, no explanation.', 'output': '[491, 505, 548, 559, 535, 622, 606, 508]'}}}]}\n",
            "\n",
            "\n",
            "{'router_workflow_2': {'llm_call_3': {'result': [{'llm_call_1': {'result': {'input': '1) What is the slope of values in the target column of df. Only return slope of target column, no explanation.', 'output': '2.657'}}}, {'llm_call_2': {'result': {'input': '2) Calculate the 95% for target column of df. Only return a list of numbers that exceed the 95% value, no explanation.', 'output': '[491, 505, 548, 559, 535, 622, 606, 508]'}}}]}}}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for step in router_workflow_2.stream(\"Two prompts are in this sentence. Please separate and return them. What is the slope of values in the target column of df. Only return slope of target column, no explanation. Calculate the 95% for target column of df. Only return a list of numbers that exceed the 95% value, no explanation.\", stream_mode=\"updates\"):\n",
        "    print(step)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h40wuwX4bYD",
        "outputId": "c7f728dd-23ac-4c3c-d029-46fc159a6f8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To find the slope of the values in the target column, we can use the numpy polyfit function. This function fits a polynomial of a specified degree to the data and returns the coefficients of the polynomial. In this case, we want a polynomial of degree 1, which is a straight line, and the coefficient of the x term will be the slope of the line.\n",
            "\n",
            "Action: python_repl_ast\n",
            "Action Input: \n",
            "```python\n",
            "import numpy as np\n",
            "slope, intercept = np.polyfit(df.index, df['target'], 1)\n",
            "slope\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3m2.657183908045976\u001b[0m\u001b[32;1m\u001b[1;3mI have calculated the slope of the values in the target column of the dataframe df.\n",
            "Final Answer: 2.657183908045976\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'llm_call_1': {'input': 'What is the slope of values in the target column of df. Only return slope of target column, no explanation. ', 'output': '2.657183908045976'}}\n",
            "\n",
            "\n",
            "{'router_workflow_1': {'input': 'What is the slope of values in the target column of df. Only return slope of target column, no explanation. ', 'output': '2.657183908045976'}}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for step in router_workflow_1.stream(\"What is the slope of values in the target column of df. Only return slope of target column, no explanation. \", stream_mode=\"updates\"):\n",
        "    print(step)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLxppcEQhgoi"
      },
      "source": [
        "### LangGraph Workflow, datafile detected from prompt rather than pre-defined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2FWyPt3ho_s"
      },
      "outputs": [],
      "source": [
        "llm_4 = ChatOpenAI(\n",
        "\tapi_key=\"replace with your api\",\n",
        "    model_name=\"gpt-4\",\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "llm_turbo = ChatOpenAI(\n",
        "\tapi_key=\"replace with your api\",\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0.7\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP9GlSYyho_s"
      },
      "outputs": [],
      "source": [
        "# agent_threshold = create_pandas_dataframe_agent(llm_turbo, df, verbose=True, allow_dangerous_code=True)\n",
        "# agent_slope = create_pandas_dataframe_agent(llm_4, df, verbose=True, allow_dangerous_code=True)\n",
        "def build_agent_from_prompt(llm, prompt: str):\n",
        "    import re\n",
        "    match = re.search(r\"[\\\"'](?P<filename>[^\\\"']+\\.csv)[\\\"']\", prompt)\n",
        "    if not match:\n",
        "        raise ValueError(\"No CSV file name found in prompt.\")\n",
        "    file_path = match.group(\"filename\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Failed to load CSV file: {file_path}\") from e\n",
        "\n",
        "    agent = create_pandas_dataframe_agent(llm, df, verbose=True, allow_dangerous_code=True)\n",
        "    return agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jfvmo10Nho_s"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END, MessagesState\n",
        "from langgraph.types import Command\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "import json\n",
        "\n",
        "class Route(BaseModel):\n",
        "    step: Literal[\"slope\", \"exceedance\", \"separate\"] = Field(\n",
        "        ..., description=\"The next step in the routing process\"\n",
        "    )\n",
        "\n",
        "router = llm_4.with_structured_output(Route)\n",
        "\n",
        "# ==== Supervisor Node ====\n",
        "def supervisor_node(state: MessagesState) -> Command:\n",
        "    user_msg = state[\"messages\"][-1].content\n",
        "    step = router.invoke([\n",
        "        SystemMessage(content=\"Route the input to slope, threshold, forecasting, or separate based on the user's request.\"),\n",
        "        HumanMessage(content=user_msg),\n",
        "    ]).step\n",
        "    return Command(update={\"messages\": state[\"messages\"]}, goto=step)\n",
        "\n",
        "\n",
        "# ==== Slope Node ====\n",
        "def slope_worker_node(state: MessagesState) -> Command:\n",
        "    prompt = state[\"messages\"][-1].content\n",
        "    agent = build_agent_from_prompt(llm_4, prompt)\n",
        "    result = agent_slope.invoke(prompt)\n",
        "    content = result.get(\"output\", str(result))\n",
        "    return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=content)]}, goto=END)\n",
        "\n",
        "# ==== Threshold Node ====\n",
        "def threshold_worker_node(state: MessagesState) -> Command:\n",
        "    prompt = state[\"messages\"][-1].content\n",
        "    agent = build_agent_from_prompt(llm_turbo, prompt)\n",
        "    result = agent.invoke(prompt)\n",
        "    content = result.get(\"output\", str(result))\n",
        "    return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=content)]}, goto=END)\n",
        "\n",
        "# ==== Separate Node ====\n",
        "def separate_worker_node(state: MessagesState) -> Command:\n",
        "    user_msg = state[\"messages\"][-1].content\n",
        "\n",
        "    result = llm_4.invoke(user_msg)\n",
        "    prompts = result.content.splitlines()\n",
        "\n",
        "    all_outputs = []\n",
        "    for prompt in prompts:\n",
        "        prompt = prompt.strip()\n",
        "        if not prompt:\n",
        "            continue\n",
        "        print(f\"[Separate] Sub-prompt: {prompt}\")\n",
        "\n",
        "        sub_state = {\"messages\": [HumanMessage(content=prompt)]}\n",
        "        sub_result = graph.invoke(sub_state)\n",
        "\n",
        "        if \"messages\" in sub_result and isinstance(sub_result[\"messages\"], list):\n",
        "            output_msg = sub_result[\"messages\"][-1]\n",
        "            if hasattr(output_msg, \"content\"):\n",
        "                all_outputs.append(f\"Prompt: {prompt}\\nResult: {output_msg.content}\")\n",
        "            else:\n",
        "                all_outputs.append(f\"Prompt: {prompt}\\nResult: [No content returned]\")\n",
        "        else:\n",
        "            all_outputs.append(f\"Prompt: {prompt}\\nResult: [Invalid result structure]\")\n",
        "\n",
        "    summary = \"\\n\\n\".join(all_outputs)\n",
        "    return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=summary)]}, goto=END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzUJML9sho_t"
      },
      "outputs": [],
      "source": [
        "builder = StateGraph(MessagesState)\n",
        "\n",
        "builder.add_node(\"supervisor\", supervisor_node)\n",
        "builder.add_node(\"slope\", slope_worker_node)\n",
        "builder.add_node(\"exceedance\", threshold_worker_node)\n",
        "builder.add_node(\"separate\", separate_worker_node)\n",
        "\n",
        "builder.set_entry_point(\"supervisor\")\n",
        "builder.add_edge(\"slope\", END)\n",
        "builder.add_edge(\"exceedance\", END)\n",
        "builder.add_edge(\"separate\", END)\n",
        "\n",
        "graph = builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "rjwGfECIho_t",
        "outputId": "edf065d6-af92-44cf-dd4f-0bae7a519856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiled graph id: 134086014345040\n",
            "Mermaid graph id: 134086014345040\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, Image\n",
        "print(\"Compiled graph id:\", id(graph))\n",
        "print(\"Mermaid graph id:\", id(graph))\n",
        "# print(graph.get_graph().draw_mermaid())\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "# print(graph.get_graph().draw_mermaid())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6Y_s_--ho_u",
        "outputId": "7cc1960c-8915-4d39-c657-2b2d51543944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Step executed:\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to load the data from the CSV file into a pandas dataframe and then calculate the 95th percentile for the 'target' column in the dataframe.\n",
            "Action: python_repl_ast\n",
            "Action Input: df = pd.read_csv('reform_AirPassengersDataset_DARTS_144.csv')\u001b[0m\u001b[36;1m\u001b[1;3mNameError: name 'pd' is not defined\u001b[0m\u001b[32;1m\u001b[1;3mI forgot to import pandas before trying to use it.\n",
            "Action: python_repl_ast\n",
            "Action Input: import pandas as pd\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mNow I can try loading the data and calculating the 95th percentile for the 'target' column.\n",
            "Action: python_repl_ast\n",
            "Action Input: df = pd.read_csv('reform_AirPassengersDataset_DARTS_144.csv')\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mNow I can calculate the 95th percentile for the 'target' column and filter the dataframe based on that.\n",
            "Action: python_repl_ast\n",
            "Action Input: percentile_95 = df['target'].quantile(0.95)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mNow I can filter the dataframe to only include values in the 'target' column that exceed the 95th percentile value.\n",
            "Action: python_repl_ast\n",
            "Action Input: df[df['target'] > percentile_95]['target'].tolist()\u001b[0m\u001b[36;1m\u001b[1;3m[491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "\n",
            "Final Answer: [491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            ">>> Step executed:\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the 95% for target column of df, then only return a list of numbers in the target column that exceed the 95% value, no explanation.\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "# result = graph.invoke(state)\n",
        "# print(result[\"messages\"][-1].content)\n",
        "for update in graph.stream(state, stream_mode=\"updates\"):\n",
        "    print(\">>> Step executed:\")\n",
        "    if \"node\" in update:\n",
        "        print(f\"  Node: {update['node']}\")\n",
        "    if \"messages\" in update:\n",
        "        for msg in update[\"messages\"]:\n",
        "            print(f\"  Message: {getattr(msg, 'content', msg)}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkOr_RU7ho_u",
        "outputId": "7ca94088-131c-444f-c342-5bdb5de1618e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Step executed:\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The question asks for the slope of the values in the target column. This suggests a linear regression problem where we consider the target values as the dependent variable and the index (or time) as the independent variable. We can use numpy.polyfit to calculate the slope.\n",
            "\n",
            "Action: python_repl_ast\n",
            "Action Input: \n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "# Create an array representing the index values\n",
            "x = np.array(df.index)\n",
            "\n",
            "# Create an array representing the target values\n",
            "y = np.array(df['target'])\n",
            "\n",
            "# Use numpy's polyfit function to calculate the slope and intercept of the best fit line\n",
            "slope, intercept = np.polyfit(x, y, 1)\n",
            "\n",
            "slope\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3m2.657183908045976\u001b[0m\u001b[32;1m\u001b[1;3mThe slope of the best fit line for the target values is approximately 2.66.\n",
            "Final Answer: 2.66\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            ">>> Step executed:\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the slope of values in the target column of df, then return the slope of target column only, no explanation.\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "# result = graph.invoke(state)\n",
        "# print(result[\"messages\"][-1].content)\n",
        "for update in graph.stream(state, stream_mode=\"updates\"):\n",
        "    print(\">>> Step executed:\")\n",
        "    if \"node\" in update:\n",
        "        print(f\"  Node: {update['node']}\")\n",
        "    if \"messages\" in update:\n",
        "        for msg in update[\"messages\"]:\n",
        "            print(f\"  Message: {getattr(msg, 'content', msg)}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ijKZuMCho_u",
        "outputId": "d1ad4f8c-3474-4de4-b93f-172563795251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Step executed:\n",
            "----------------------------------------\n",
            "[Separate] Sub-prompt: 1) Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the slope of values in the target column of df and only return slope of target column, no explanation.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To calculate the slope of the values in the target column, I'll need to do a linear regression. A simple way to do this in Python is using numpy's polyfit function, which can fit a polynomial of a specified degree to data and returns the coefficients of the polynomial. In this case, a degree of 1 is used to fit a straight line. The slope is the first coefficient returned by polyfit.\n",
            "Action: python_repl_ast\n",
            "Action Input: \n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "x = np.arange(len(df))\n",
            "y = df['target']\n",
            "slope, intercept = np.polyfit(x, y, 1)\n",
            "slope\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3m2.657183908045976\u001b[0m\u001b[32;1m\u001b[1;3mI have calculated the slope of the target column using numpy's polyfit for linear regression.\n",
            "Final Answer: The slope of the target column is approximately 2.66.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "[Separate] Sub-prompt: 2) Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the 95% for target column of df. Only return a list of numbers that exceed the 95% value, no explanation.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to load the file 'reform_AirPassengersDataset_DARTS_144.csv' and calculate the 95th percentile for the 'target' column in the dataframe.\n",
            "Action: python_repl_ast\n",
            "Action Input: df['target'].quantile(0.95)\u001b[0m\u001b[36;1m\u001b[1;3m488.14999999999986\u001b[0m\u001b[32;1m\u001b[1;3mI need to filter out the numbers that exceed 488.15 from the 'target' column.\n",
            "Action: python_repl_ast\n",
            "Action Input: df[df['target'] > 488.15]['target'].tolist()\u001b[0m\u001b[36;1m\u001b[1;3m[491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: [491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            ">>> Step executed:\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "initial_state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Two prompts are in this sentence. Please separate and return them. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the slope of values in the target column of df and only return slope of target column, no explanation. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the 95% for target column of df. Only return a list of numbers that exceed the 95% value, no explanation.\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "# result = graph.invoke(initial_state)\n",
        "# print(result[\"messages\"][-1].content)\n",
        "for update in graph.stream(initial_state, stream_mode=\"updates\"):\n",
        "    print(\">>> Step executed:\")\n",
        "    if \"node\" in update:\n",
        "        print(f\"  Node: {update['node']}\")\n",
        "    if \"messages\" in update:\n",
        "        for msg in update[\"messages\"]:\n",
        "            print(f\"  Message: {getattr(msg, 'content', msg)}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMc4_QdIxTIi"
      },
      "source": [
        "### Integrate with Chronos for Forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-2Hi458xYcS"
      },
      "outputs": [],
      "source": [
        "llm_4 = ChatOpenAI(\n",
        "\tapi_key=\"replace with your api\",\n",
        "    model_name=\"gpt-4\",\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "llm_turbo = ChatOpenAI(\n",
        "\tapi_key=\"replace with your api\",\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0.7\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0epjdRWUxYcS"
      },
      "outputs": [],
      "source": [
        "# agent_threshold = create_pandas_dataframe_agent(llm_turbo, df, verbose=True, allow_dangerous_code=True)\n",
        "# agent_slope = create_pandas_dataframe_agent(llm_4, df, verbose=True, allow_dangerous_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSzkIsMTxYcS"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END, MessagesState\n",
        "from langgraph.types import Command\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "import json\n",
        "\n",
        "class Route(BaseModel):\n",
        "    step: Literal[\"forecast\", \"threshold_exceedance\", \"slope_calculation\", \"separate\"] = Field(\n",
        "        ..., description=\"The next step in the routing process\"\n",
        "    )\n",
        "\n",
        "router = llm_4.with_structured_output(Route)\n",
        "\n",
        "# ==== Supervisor Node ====\n",
        "def llm_supervisor_node(state: MessagesState) -> Command[str]:\n",
        "    user_msg = state[\"messages\"][-1].content\n",
        "    step = router.invoke([\n",
        "        SystemMessage(content=\"Route the input to forecast, threshold_exceedance, slope_calculation, or separate based on the user's request.\"),\n",
        "        HumanMessage(content=user_msg),\n",
        "    ]).step\n",
        "    return Command(update={\"messages\": state[\"messages\"]}, goto=step)\n",
        "\n",
        "# ==== Forecast Node ====\n",
        "def chronos_forecast_node(state: MessagesState) -> Command:\n",
        "    user_msg = state[\"messages\"][-1].content\n",
        "    import re, json\n",
        "    match = re.search(r\"'([^']+\\.csv)'\", user_msg)\n",
        "    pred_len_match = re.search(r\"(\\d+)\\s+(?:days|steps)\", user_msg)\n",
        "\n",
        "    if not match or not pred_len_match:\n",
        "        return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=\"Error: Missing file path or prediction length.\")]}, goto=\"end\")\n",
        "\n",
        "    file_path = match.group(1)\n",
        "    pred_len = int(pred_len_match.group(1))\n",
        "\n",
        "    df = pd.read_csv(file_path)[[\"item_id\", \"timestamp\", \"target\"]]\n",
        "    tsdf = TimeSeriesDataFrame.from_data_frame(df, id_column=\"item_id\", timestamp_column=\"timestamp\")\n",
        "    train_data, test_data = tsdf.train_test_split(pred_len)\n",
        "    predictor = TimeSeriesPredictor(prediction_length=pred_len).fit(train_data, presets=\"bolt_small\")\n",
        "    predictions = predictor.predict(train_data)\n",
        "    leaderboard = predictor.leaderboard(test_data)\n",
        "    model_name = leaderboard.iloc[0][\"model\"]\n",
        "    mape = -leaderboard.iloc[0][\"score_test\"]\n",
        "\n",
        "    predictions_df = predictions.to_data_frame().reset_index()\n",
        "    preview = predictions_df[[\"item_id\", \"timestamp\", \"mean\"]].tail(10).to_string(index=False)\n",
        "    result = f\"Top model: {model_name}, MAPE: {mape * 100:.2f}%\\nForecast Preview:\\n{preview}\"\n",
        "\n",
        "    return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=result)]}, goto=\"end\")\n",
        "\n",
        "\n",
        "# ==== build agent for LangChain Pandas to use ====\n",
        "def build_agent_from_prompt(llm, prompt: str):\n",
        "    import re\n",
        "    match = re.search(r\"[\\\"'](?P<filename>[^\\\"']+\\.csv)[\\\"']\", prompt)\n",
        "    if not match:\n",
        "        raise ValueError(\"No CSV file name found in prompt.\")\n",
        "    file_path = match.group(\"filename\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Failed to load CSV file: {file_path}\") from e\n",
        "\n",
        "    agent = create_pandas_dataframe_agent(llm, df, verbose=True, allow_dangerous_code=True)\n",
        "    return agent\n",
        "\n",
        "# ==== Slope Node ====\n",
        "def slope_agent_node(state: MessagesState) -> Command:\n",
        "    prompt = state[\"messages\"][-1].content\n",
        "    agent = build_agent_from_prompt(llm_4, prompt)\n",
        "    result = agent.invoke(prompt)\n",
        "    content = result.get(\"output\", str(result))\n",
        "    return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=content)]}, goto=\"end\")\n",
        "\n",
        "# ==== Threshold Node ====\n",
        "def threshold_agent_node(state: MessagesState) -> Command:\n",
        "    prompt = state[\"messages\"][-1].content\n",
        "    agent = build_agent_from_prompt(llm_turbo, prompt)\n",
        "    result = agent.invoke(prompt)\n",
        "    content = result.get(\"output\", str(result))\n",
        "    return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=content)]}, goto=\"end\")\n",
        "\n",
        "# ==== Separate Node ====\n",
        "def separate_worker_node(state: MessagesState) -> Command:\n",
        "    user_msg = state[\"messages\"][-1].content\n",
        "\n",
        "    result = llm_4.invoke(user_msg)\n",
        "    prompts = result.content.splitlines()\n",
        "\n",
        "    all_outputs = []\n",
        "    for prompt in prompts:\n",
        "        prompt = prompt.strip()\n",
        "        if not prompt:\n",
        "            continue\n",
        "        print(f\"[Separate] Sub-prompt: {prompt}\")\n",
        "\n",
        "        sub_state = {\"messages\": [HumanMessage(content=prompt)]}\n",
        "        sub_result = graph.invoke(sub_state)\n",
        "\n",
        "        if \"messages\" in sub_result and isinstance(sub_result[\"messages\"], list):\n",
        "            output_msg = sub_result[\"messages\"][-1]\n",
        "            if hasattr(output_msg, \"content\"):\n",
        "                all_outputs.append(f\"Prompt: {prompt}\\nResult: {output_msg.content}\")\n",
        "            else:\n",
        "                all_outputs.append(f\"Prompt: {prompt}\\nResult: [No content returned]\")\n",
        "        else:\n",
        "            all_outputs.append(f\"Prompt: {prompt}\\nResult: [Invalid result structure]\")\n",
        "\n",
        "    summary = \"\\n\\n\".join(all_outputs)\n",
        "    return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=summary)]}, goto=\"end\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF32cILdxYcT"
      },
      "outputs": [],
      "source": [
        "builder = StateGraph(MessagesState)\n",
        "\n",
        "builder.add_node(\"supervisor\", llm_supervisor_node)\n",
        "builder.add_node(\"forecast\", chronos_forecast_node)\n",
        "builder.add_node(\"threshold_exceedance\", threshold_agent_node)\n",
        "builder.add_node(\"slope_calculation\", slope_agent_node)\n",
        "builder.add_node(\"separate\", separate_worker_node)\n",
        "\n",
        "builder.set_entry_point(\"supervisor\")\n",
        "builder.add_edge(\"forecast\", END)\n",
        "builder.add_edge(\"threshold_exceedance\", END)\n",
        "builder.add_edge(\"slope_calculation\", END)\n",
        "builder.add_edge(\"separate\", END)\n",
        "\n",
        "graph = builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "4BQi7obbxYcT",
        "outputId": "e5496d5e-4e53-4151-d62c-16f4236ba77a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiled graph id: 134086013153616\n",
            "Mermaid graph id: 134086013153616\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, Image\n",
        "print(\"Compiled graph id:\", id(graph))\n",
        "print(\"Mermaid graph id:\", id(graph))\n",
        "# print(graph.get_graph().draw_mermaid())\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "# print(graph.get_graph().draw_mermaid())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHxSTf8i7eH7"
      },
      "source": [
        "#### invoke the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP-CcCMyxYcT",
        "outputId": "81e31088-cdb2-4593-f15f-fa2b10f5a90e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Step executed:\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to load the data from the CSV file and calculate the 95% threshold for the target column in the dataframe.\n",
            "Action: python_repl_ast\n",
            "Action Input: df = pd.read_csv('reform_AirPassengersDataset_DARTS_144.csv')\u001b[0m\u001b[36;1m\u001b[1;3mNameError: name 'pd' is not defined\u001b[0m\u001b[32;1m\u001b[1;3mI forgot to import the pandas library before using it.\n",
            "Action: python_repl_ast\n",
            "Action Input: import pandas as pd\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mNow that I have imported pandas, I can load the data from the CSV file and proceed with the calculations.\n",
            "Action: python_repl_ast\n",
            "Action Input: df = pd.read_csv('reform_AirPassengersDataset_DARTS_144.csv')\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mI need to calculate the 95th percentile value for the 'target' column in the dataframe.\n",
            "Action: python_repl_ast\n",
            "Action Input: percentile_95 = df['target'].quantile(0.95)\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mNow, I need to filter the dataframe to only include values in the 'target' column that exceed the 95th percentile value.\n",
            "Action: python_repl_ast\n",
            "Action Input: df[df['target'] > percentile_95]['target'].tolist()\u001b[0m\u001b[36;1m\u001b[1;3m[491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: [491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            ">>> Step executed:\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ==== threshold exceedance task ====\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the 95% threshold for target column of df, then only return a list of numbers in the target column that exceed the 95% value, no explanation.\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "# result = graph.invoke(state)\n",
        "# print(result[\"messages\"][-1].content)\n",
        "for update in graph.stream(state, stream_mode=\"updates\"):\n",
        "    print(\">>> Step executed:\")\n",
        "    if \"node\" in update:\n",
        "        print(f\"  Node: {update['node']}\")\n",
        "    if \"messages\" in update:\n",
        "        for msg in update[\"messages\"]:\n",
        "            print(f\"  Message: {getattr(msg, 'content', msg)}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1MJZTBhxYcT",
        "outputId": "fe072d81-43ae-4e29-df3b-8d20870296c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Step executed:\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To calculate the slope of values in the target column, I need to perform a linear regression on this data set. The slope of the regression line is the value we need. I can use the `linregress` function from the `scipy.stats` library to do this.\n",
            "Action: python_repl_ast\n",
            "Action Input: \n",
            "```python\n",
            "from scipy.stats import linregress\n",
            "\n",
            "# Add an index column to the dataframe for calculation of slope\n",
            "df['index'] = df.index\n",
            "\n",
            "# Perform linear regression\n",
            "slope, _, _, _, _ = linregress(df['index'], df['target'])\n",
            "\n",
            "slope\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3m2.657183908045977\u001b[0m\u001b[32;1m\u001b[1;3mI have calculated the slope of the target column.\n",
            "Final Answer: The slope of the target column is approximately 2.657.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            ">>> Step executed:\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ==== slope calculation task ====\n",
        "state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the slope of values in the target column of df, then return the slope of target column only, no explanation.\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "# result = graph.invoke(state)\n",
        "# print(result[\"messages\"][-1].content)\n",
        "for update in graph.stream(state, stream_mode=\"updates\"):\n",
        "    print(\">>> Step executed:\")\n",
        "    if \"node\" in update:\n",
        "        print(f\"  Node: {update['node']}\")\n",
        "    if \"messages\" in update:\n",
        "        for msg in update[\"messages\"]:\n",
        "            print(f\"  Message: {getattr(msg, 'content', msg)}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gwfr4SQZ7wX7"
      },
      "source": [
        "results from previous two tasks are both correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "473a01fc09bd4367839b1d67abe4fb80",
            "8b4d0d7a40d046c19b3f0a9a708fd80e",
            "55d2258afa1c41efa5e644abe2e92515",
            "e765d47e43c94c128fe3fe09689f0760",
            "3cadc4f82c194d6a83fdee05c3276533",
            "ce98bf65896143c6ac473a6a83e2f14e",
            "7dd71527c13c4111a88a2939f68b49ec",
            "bc33be7ba3d24a4faa61dc4643a47d95",
            "1ef1b50c7d814957b4cef01ee66fbb72",
            "cee4d2b4e652465db07a53a693bf6c68",
            "7d9a148eb4d7485d82ecba67a5a2d189",
            "8c31254a2eab45af9b1b6e165140ae27",
            "1cb4ca320ad748c080fc230ec9b1f77d",
            "a56df7d393a645dbb8d4b7f7a424bac8",
            "a57b4775f928416689cc368b66e76c45",
            "3a8bacb16f3443119435b8c2e4bd5aad",
            "ce9993db03464544b95a8d1d37fd23d6",
            "564d92ece0944ac1a252b80bc2be3d50",
            "dde0805a77514e0bbd89bb36ca0d6271",
            "3fcc0f93e8464820bac4f0536c19e267",
            "5ee112ce9b2b4185bc11872df7d6f608",
            "eadf7d37d00a44b68f208afcb08dea16"
          ]
        },
        "id": "Ys_Br1iv01mZ",
        "outputId": "0abda645-4dbf-473a-90ab-07d9d193c284"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Beginning AutoGluon training...\n",
            "AutoGluon will save models to '/content/drive/MyDrive/GE_Capstone/AI Agent Workflow/AutogluonModels/ag-20250413_020546'\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2.1b20250412\n",
            "Python Version:     3.11.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "GPU Count:          0\n",
            "Memory Avail:       10.95 GB / 12.67 GB (86.4%)\n",
            "Disk Space Avail:   63.85 GB / 107.72 GB (59.3%)\n",
            "===================================================\n",
            "Setting presets to: bolt_small\n",
            "\n",
            "Fitting with arguments:\n",
            "{'enable_ensemble': True,\n",
            " 'eval_metric': WQL,\n",
            " 'hyperparameters': {'Chronos': {'model_path': 'bolt_small'}},\n",
            " 'known_covariates_names': [],\n",
            " 'num_val_windows': 1,\n",
            " 'prediction_length': 24,\n",
            " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
            " 'random_seed': 123,\n",
            " 'refit_every_n_windows': 1,\n",
            " 'refit_full': False,\n",
            " 'skip_model_selection': True,\n",
            " 'target': 'target',\n",
            " 'verbosity': 2}\n",
            "\n",
            "Inferred time series frequency: 'MS'\n",
            "Provided train_data has 120 rows, 1 time series. Median time series length is 120 (min=120, max=120). \n",
            "\n",
            "Provided data contains following columns:\n",
            "\ttarget: 'target'\n",
            "\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "===================================================\n",
            "\n",
            "Starting training. Start time is 2025-04-13 02:05:52\n",
            "Models that will be trained: ['Chronos[bolt_small]']\n",
            "Training timeseries model Chronos[bolt_small]. \n",
            "\t28.36   s     = Training runtime\n",
            "Training complete. Models trained: ['Chronos[bolt_small]']\n",
            "Total runtime: 28.43 s\n",
            "Best model: Chronos[bolt_small]\n",
            "Model not specified in predict, will default to the model with the best validation score: Chronos[bolt_small]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "473a01fc09bd4367839b1d67abe4fb80",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c31254a2eab45af9b1b6e165140ae27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/191M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top model: Chronos[bolt_small], MAPE: 5.04%\n",
            "Forecast Preview:\n",
            " item_id  timestamp       mean\n",
            "       1 1960-03-01 414.699951\n",
            "       1 1960-04-01 419.955566\n",
            "       1 1960-05-01 428.213074\n",
            "       1 1960-06-01 483.538208\n",
            "       1 1960-07-01 525.270935\n",
            "       1 1960-08-01 521.030457\n",
            "       1 1960-09-01 468.151520\n",
            "       1 1960-10-01 409.785828\n",
            "       1 1960-11-01 384.249237\n",
            "       1 1960-12-01 402.730347\n"
          ]
        }
      ],
      "source": [
        "# ==== forecasting task ====\n",
        "initial_state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Please forecast the next 24 days using the file 'reform_AirPassengersDataset_DARTS_144.csv'.\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "result = graph.invoke(initial_state)\n",
        "print(result[\"messages\"][-1].content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJq7YUZUxYcT",
        "outputId": "1a46038e-1bd6-4704-9814-9b9a888542f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Step executed:\n",
            "----------------------------------------\n",
            "[Separate] Sub-prompt: 1. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the slope of values in the target column of df and only return slope of target column, no explanation.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To calculate the slope of the values in the 'target' column, we first need to ensure that the data is sorted in ascending order by the 'timestamp' column. After sorting the data, we can use the numpy polyfit function to fit a line to the data points and get the slope of the line. The numpy polyfit function takes three arguments: x-coordinates of the data points, y-coordinates of the data points, and the degree of the polynomial to fit. We can set the degree to 1 to fit a line to the data points. The polyfit function returns the coefficients of the polynomial in order of decreasing powers. The first coefficient is the slope of the line.\n",
            "\n",
            "Action: python_repl_ast\n",
            "Action Input: \n",
            "```\n",
            "import numpy as np\n",
            "\n",
            "# Ensure that the data is sorted in ascending order by the 'timestamp' column\n",
            "df = df.sort_values('timestamp')\n",
            "\n",
            "# Use numpy polyfit to fit a line to the data points in the 'target' column and get the slope of the line\n",
            "slope, intercept = np.polyfit(range(len(df)), df['target'], 1)\n",
            "slope\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3m2.657183908045976\u001b[0m\u001b[32;1m\u001b[1;3mThe slope of the values in the 'target' column of the dataframe 'df' is approximately 2.657. This means that, on average, the 'target' value increases by about 2.657 for each increase in the index (which corresponds to each next timestamp in ascending order).\n",
            "Final Answer: The slope of the values in the 'target' column of the dataframe 'df' is approximately 2.657.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "[Separate] Sub-prompt: 2. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the 95% for target column of df. Only return a list of numbers that exceed the 95% value, no explanation.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to load the file 'reform_AirPassengersDataset_DARTS_144.csv' and calculate the 95th percentile for the target column in the dataframe `df`.\n",
            "Action: python_repl_ast\n",
            "Action Input: df['target'].quantile(0.95)\u001b[0m\u001b[36;1m\u001b[1;3m488.14999999999986\u001b[0m\u001b[32;1m\u001b[1;3mNow I need to filter the values in the 'target' column that exceed the 95th percentile value.\n",
            "Action: python_repl_ast\n",
            "Action Input: df[df['target'] > df['target'].quantile(0.95)]['target'].tolist()\u001b[0m\u001b[36;1m\u001b[1;3m[491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: [491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            ">>> Step executed:\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ==== threshold exceedance & slope calculation task in one prompt ====\n",
        "\n",
        "initial_state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Two prompts are in this sentence. Please separate and return them. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the slope of values in the target column of df and only return slope of target column, no explanation. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the 95% for target column of df. Only return a list of numbers that exceed the 95% value, no explanation.\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "# result = graph.invoke(initial_state)\n",
        "# print(result[\"messages\"][-1].content)\n",
        "for update in graph.stream(initial_state, stream_mode=\"updates\"):\n",
        "    print(\">>> Step executed:\")\n",
        "    if \"node\" in update:\n",
        "        print(f\"  Node: {update['node']}\")\n",
        "    if \"messages\" in update:\n",
        "        for msg in update[\"messages\"]:\n",
        "            print(f\"  Message: {getattr(msg, 'content', msg)}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeBGrh_h56N2",
        "outputId": "343d7b80-e0f5-42e4-ca36-fef98090110f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Separate] Sub-prompt: 1. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the slope of values in the target column of df and only return slope of target column, no explanation.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To calculate the slope of a line, we use the formula (y2 - y1) / (x2 - x1). Here, x is the index of the dataframe and y is the target value. We can get the values of y and x from the dataframe, df. \n",
            "\n",
            "Action: python_repl_ast\n",
            "Action Input: \n",
            "```python\n",
            "import numpy as np\n",
            "y = df['target'].values\n",
            "x = np.arange(len(y))\n",
            "slope = (y[-1] - y[0]) / (x[-1] - x[0])\n",
            "slope\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3m2.237762237762238\u001b[0m\u001b[32;1m\u001b[1;3mI have successfully calculated the slope of the target column.\n",
            "Final Answer: 2.237762237762238\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "[Separate] Sub-prompt: 2. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the 95% for target column of df, and only return a list of numbers that exceed the 95% value, no explanation.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: We need to load the 'reform_AirPassengersDataset_DARTS_144.csv' file and calculate the 95th percentile for the target column in the dataframe `df`.\n",
            "Action: python_repl_ast\n",
            "Action Input: df['target'].quantile(0.95)\u001b[0m\u001b[36;1m\u001b[1;3m488.14999999999986\u001b[0m\u001b[32;1m\u001b[1;3mWe need to filter the target column in `df` to only include numbers that exceed the 95th percentile value of 488.15.\n",
            "Action: python_repl_ast\n",
            "Action Input: df[df['target'] > df['target'].quantile(0.95)]['target'].tolist()\u001b[0m\u001b[36;1m\u001b[1;3m[491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: [491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "[Separate] Sub-prompt: 3. Forecast the next 24 days using the file 'reform_AirPassengersDataset_DARTS_144.csv'.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Beginning AutoGluon training...\n",
            "AutoGluon will save models to '/content/drive/MyDrive/GE_Capstone/AI Agent Workflow/AutogluonModels/ag-20250413_021011'\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2.1b20250412\n",
            "Python Version:     3.11.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "GPU Count:          0\n",
            "Memory Avail:       10.21 GB / 12.67 GB (80.6%)\n",
            "Disk Space Avail:   63.63 GB / 107.72 GB (59.1%)\n",
            "===================================================\n",
            "Setting presets to: bolt_small\n",
            "\n",
            "Fitting with arguments:\n",
            "{'enable_ensemble': True,\n",
            " 'eval_metric': WQL,\n",
            " 'hyperparameters': {'Chronos': {'model_path': 'bolt_small'}},\n",
            " 'known_covariates_names': [],\n",
            " 'num_val_windows': 1,\n",
            " 'prediction_length': 24,\n",
            " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
            " 'random_seed': 123,\n",
            " 'refit_every_n_windows': 1,\n",
            " 'refit_full': False,\n",
            " 'skip_model_selection': True,\n",
            " 'target': 'target',\n",
            " 'verbosity': 2}\n",
            "\n",
            "Inferred time series frequency: 'MS'\n",
            "Provided train_data has 120 rows, 1 time series. Median time series length is 120 (min=120, max=120). \n",
            "\n",
            "Provided data contains following columns:\n",
            "\ttarget: 'target'\n",
            "\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "===================================================\n",
            "\n",
            "Starting training. Start time is 2025-04-13 02:10:11\n",
            "Models that will be trained: ['Chronos[bolt_small]']\n",
            "Training timeseries model Chronos[bolt_small]. \n",
            "\t0.01    s     = Training runtime\n",
            "Training complete. Models trained: ['Chronos[bolt_small]']\n",
            "Total runtime: 0.05 s\n",
            "Best model: Chronos[bolt_small]\n",
            "Model not specified in predict, will default to the model with the best validation score: Chronos[bolt_small]\n",
            "Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: 1. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the slope of values in the target column of df and only return slope of target column, no explanation.\n",
            "Result: 2.237762237762238\n",
            "\n",
            "Prompt: 2. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the 95% for target column of df, and only return a list of numbers that exceed the 95% value, no explanation.\n",
            "Result: [491, 505, 548, 559, 535, 622, 606, 508]\n",
            "\n",
            "Prompt: 3. Forecast the next 24 days using the file 'reform_AirPassengersDataset_DARTS_144.csv'.\n",
            "Result: Top model: Chronos[bolt_small], MAPE: 5.04%\n",
            "Forecast Preview:\n",
            " item_id  timestamp       mean\n",
            "       1 1960-03-01 414.699951\n",
            "       1 1960-04-01 419.955566\n",
            "       1 1960-05-01 428.213074\n",
            "       1 1960-06-01 483.538208\n",
            "       1 1960-07-01 525.270935\n",
            "       1 1960-08-01 521.030457\n",
            "       1 1960-09-01 468.151520\n",
            "       1 1960-10-01 409.785828\n",
            "       1 1960-11-01 384.249237\n",
            "       1 1960-12-01 402.730347\n"
          ]
        }
      ],
      "source": [
        "# ==== threshold exceedance & slope calculation & forecasting task in one prompt ====\n",
        "\n",
        "initial_state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Three prompts are in this sentence. Please separate and return them. First use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the slope of values in the target column of df and only return slope of target column, no explanation. Secondly use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the 95% for target column of df, and only return a list of numbers that exceed the 95% value, no explanation. Finally forecast the next 24 days using the file 'reform_AirPassengersDataset_DARTS_144.csv'.\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "result = graph.invoke(initial_state)\n",
        "print(result[\"messages\"][-1].content)\n",
        "# for update in graph.stream(initial_state, stream_mode=\"updates\"):\n",
        "#     print(\">>> Step executed:\")\n",
        "#     if \"node\" in update:\n",
        "#         print(f\"  Node: {update['node']}\")\n",
        "#     if \"messages\" in update:\n",
        "#         for msg in update[\"messages\"]:\n",
        "#             print(f\"  Message: {getattr(msg, 'content', msg)}\")\n",
        "#     print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYaofRIqUF5d"
      },
      "source": [
        "### Integrate with text analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90sQ6wiHUF5d"
      },
      "outputs": [],
      "source": [
        "llm_4 = ChatOpenAI(\n",
        "\tapi_key=\"replace with your api\",\n",
        "    model_name=\"gpt-4\",\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "llm_turbo = ChatOpenAI(\n",
        "\tapi_key=\"replace with your api\",\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "llm_o3mini = ChatOpenAI(\n",
        "\tapi_key=\"replace with your api\",\n",
        "    model_name=\"o3-mini\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu6-hxesUF5e",
        "outputId": "a7d6e5bc-17b0-4bad-e218-9b6ddde44eea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1660: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph, END, MessagesState\n",
        "from langgraph.types import Command\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "import json\n",
        "\n",
        "class Route(BaseModel):\n",
        "    step: Literal[\"forecast\", \"threshold_exceedance\", \"slope_calculation\", \"separate\", \"text_analysis\"] = Field(\n",
        "        ..., description=\"The next step in the routing process\"\n",
        "    )\n",
        "\n",
        "router = llm_4.with_structured_output(Route)\n",
        "\n",
        "# ==== Supervisor Node ====\n",
        "def llm_supervisor_node(state: MessagesState) -> Command[str]:\n",
        "    user_msg = state[\"messages\"][-1].content\n",
        "    step = router.invoke([\n",
        "        SystemMessage(content=\"Route the input to forecast, threshold_exceedance, slope_calculation, text_analysis, or separate based on the user's request.\"),\n",
        "        HumanMessage(content=user_msg),\n",
        "    ]).step\n",
        "    return Command(update={\"messages\": state[\"messages\"]}, goto=step)\n",
        "\n",
        "# ==== Forecast Node ====\n",
        "def chronos_forecast_node(state: MessagesState) -> Command:\n",
        "    user_msg = state[\"messages\"][-1].content\n",
        "    import re, json\n",
        "    match = re.search(r\"'([^']+\\.csv)'\", user_msg)\n",
        "    pred_len_match = re.search(r\"(\\d+)\\s+(?:days|steps)\", user_msg)\n",
        "\n",
        "    if not match or not pred_len_match:\n",
        "        return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=\"Error: Missing file path or prediction length.\")]}, goto=\"end\")\n",
        "\n",
        "    file_path = match.group(1)\n",
        "    pred_len = int(pred_len_match.group(1))\n",
        "\n",
        "    df = pd.read_csv(file_path)[[\"item_id\", \"timestamp\", \"target\"]]\n",
        "    tsdf = TimeSeriesDataFrame.from_data_frame(df, id_column=\"item_id\", timestamp_column=\"timestamp\")\n",
        "    train_data, test_data = tsdf.train_test_split(pred_len)\n",
        "    predictor = TimeSeriesPredictor(prediction_length=pred_len).fit(train_data, presets=\"bolt_small\")\n",
        "    predictions = predictor.predict(train_data)\n",
        "    leaderboard = predictor.leaderboard(test_data)\n",
        "    model_name = leaderboard.iloc[0][\"model\"]\n",
        "    mape = -leaderboard.iloc[0][\"score_test\"]\n",
        "\n",
        "    predictions_df = predictions.to_data_frame().reset_index()\n",
        "    preview = predictions_df[[\"item_id\", \"timestamp\", \"mean\"]].tail(10).to_string(index=False)\n",
        "    result = f\"Top model: {model_name}, MAPE: {mape * 100:.2f}%\\nForecast Preview:\\n{preview}\"\n",
        "\n",
        "    return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=result)]}, goto=\"end\")\n",
        "\n",
        "\n",
        "# ==== build agent for LangChain Pandas to use ====\n",
        "def build_agent_from_prompt(llm, prompt: str):\n",
        "    import re\n",
        "    match = re.search(r\"[\\\"'](?P<filename>[^\\\"']+\\.csv)[\\\"']\", prompt)\n",
        "    if not match:\n",
        "        raise ValueError(\"No CSV file name found in prompt.\")\n",
        "    file_path = match.group(\"filename\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Failed to load CSV file: {file_path}\") from e\n",
        "\n",
        "    agent = create_pandas_dataframe_agent(llm, df, verbose=True, allow_dangerous_code=True)\n",
        "    return agent\n",
        "\n",
        "# ==== Slope Node ====\n",
        "def slope_agent_node(state: MessagesState) -> Command:\n",
        "    prompt = state[\"messages\"][-1].content\n",
        "    agent = build_agent_from_prompt(llm_4, prompt)\n",
        "    result = agent.invoke(prompt)\n",
        "    content = result.get(\"output\", str(result))\n",
        "    return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=content)]}, goto=\"end\")\n",
        "\n",
        "# ==== Threshold Node ====\n",
        "def threshold_agent_node(state: MessagesState) -> Command:\n",
        "    prompt = state[\"messages\"][-1].content\n",
        "    agent = build_agent_from_prompt(llm_turbo, prompt)\n",
        "    result = agent.invoke(prompt)\n",
        "    content = result.get(\"output\", str(result))\n",
        "    return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=content)]}, goto=\"end\")\n",
        "\n",
        "# === Text Analysis Node ===\n",
        "def text_analysis_node(state: MessagesState) -> Command:\n",
        "    user_msg = state[\"messages\"][-1].content\n",
        "    match = re.search(r\"'([^']+\\.txt)'\", user_msg)\n",
        "    if not match:\n",
        "        return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=\"Error: Missing .txt file in prompt.\")]}, goto=\"end\")\n",
        "    file_path = match.group(1)\n",
        "\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            content = f.read()\n",
        "    except Exception as e:\n",
        "        return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=f\"Failed to load file: {e}\")]} , goto=\"end\")\n",
        "\n",
        "    documents = [Document(page_content=content)]\n",
        "\n",
        "    embedding_model = OpenAIEmbeddings(openai_api_key=\"replace with your api\")\n",
        "    vectorstore = FAISS.from_documents(documents, embedding_model)\n",
        "    qa_chain = RetrievalQA.from_chain_type(llm=llm_o3mini, retriever=vectorstore.as_retriever())\n",
        "\n",
        "    query = state[\"messages\"][-1].content\n",
        "    result = qa_chain.invoke(query)\n",
        "    return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=result['result'])]}, goto=\"end\")\n",
        "\n",
        "# ==== Separate Node ====\n",
        "def separate_worker_node(state: MessagesState) -> Command:\n",
        "    user_msg = state[\"messages\"][-1].content\n",
        "\n",
        "    result = llm_4.invoke(user_msg)\n",
        "    prompts = result.content.splitlines()\n",
        "\n",
        "    all_outputs = []\n",
        "    for prompt in prompts:\n",
        "        prompt = prompt.strip()\n",
        "        if not prompt:\n",
        "            continue\n",
        "        print(f\"[Separate] Sub-prompt: {prompt}\")\n",
        "\n",
        "        sub_state = {\"messages\": [HumanMessage(content=prompt)]}\n",
        "        sub_result = graph.invoke(sub_state)\n",
        "\n",
        "        if \"messages\" in sub_result and isinstance(sub_result[\"messages\"], list):\n",
        "            output_msg = sub_result[\"messages\"][-1]\n",
        "            if hasattr(output_msg, \"content\"):\n",
        "                all_outputs.append(f\"Prompt: {prompt}\\nResult: {output_msg.content}\")\n",
        "            else:\n",
        "                all_outputs.append(f\"Prompt: {prompt}\\nResult: [No content returned]\")\n",
        "        else:\n",
        "            all_outputs.append(f\"Prompt: {prompt}\\nResult: [Invalid result structure]\")\n",
        "\n",
        "    summary = \"\\n\\n\".join(all_outputs)\n",
        "    return Command(update={\"messages\": state[\"messages\"] + [AIMessage(content=summary)]}, goto=\"end\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbrD8bW2UF5e"
      },
      "outputs": [],
      "source": [
        "builder = StateGraph(MessagesState)\n",
        "\n",
        "builder.add_node(\"supervisor\", llm_supervisor_node)\n",
        "builder.add_node(\"forecast\", chronos_forecast_node)\n",
        "builder.add_node(\"threshold_exceedance\", threshold_agent_node)\n",
        "builder.add_node(\"slope_calculation\", slope_agent_node)\n",
        "builder.add_node(\"text_analysis\", text_analysis_node)\n",
        "builder.add_node(\"separate\", separate_worker_node)\n",
        "\n",
        "builder.set_entry_point(\"supervisor\")\n",
        "builder.add_edge(\"forecast\", END)\n",
        "builder.add_edge(\"threshold_exceedance\", END)\n",
        "builder.add_edge(\"slope_calculation\", END)\n",
        "builder.add_edge(\"text_analysis\", END)\n",
        "builder.add_edge(\"separate\", END)\n",
        "\n",
        "graph = builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "_sH6-KTSUF5e",
        "outputId": "8dbf398c-d9be-477c-8579-7ee8ada7f6a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiled graph id: 134499259869200\n",
            "Mermaid graph id: 134499259869200\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, Image\n",
        "print(\"Compiled graph id:\", id(graph))\n",
        "print(\"Mermaid graph id:\", id(graph))\n",
        "# print(graph.get_graph().draw_mermaid())\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "# print(graph.get_graph().draw_mermaid())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee124LgdUF5f"
      },
      "source": [
        "#### invoke the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_lBEqVMUF5f",
        "outputId": "7b967f64-736c-455e-84ae-bfc0832cd6e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Step executed:\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to load the data from the file and calculate the 95% threshold for the target column in the dataframe `df`.\n",
            "\n",
            "Action: python_repl_ast\n",
            "Action Input: df['target'].quantile(0.95)\u001b[0m\u001b[36;1m\u001b[1;3m488.14999999999986\u001b[0m\u001b[32;1m\u001b[1;3mNow I need to filter the target column based on the 95% threshold.\n",
            "\n",
            "Action: python_repl_ast\n",
            "Action Input: df[df['target'] > df['target'].quantile(0.95)]['target'].tolist()\u001b[0m\u001b[36;1m\u001b[1;3m[491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "\n",
            "Final Answer: [491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            ">>> Step executed:\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ==== threshold exceedance task ====\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the 95% threshold for target column of df, then only return a list of numbers in the target column that exceed the 95% value, no explanation.\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "# result = graph.invoke(state)\n",
        "# print(result[\"messages\"][-1].content)\n",
        "for update in graph.stream(state, stream_mode=\"updates\"):\n",
        "    print(\">>> Step executed:\")\n",
        "    if \"node\" in update:\n",
        "        print(f\"  Node: {update['node']}\")\n",
        "    if \"messages\" in update:\n",
        "        for msg in update[\"messages\"]:\n",
        "            print(f\"  Message: {getattr(msg, 'content', msg)}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4FnIjzkUF5f",
        "outputId": "0c15cac1-bd9b-4928-b91e-f4c748aefd1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Step executed:\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The question is asking to calculate the slope of values in the target column of the dataframe df. To do this, we will first need to ensure that the data in the target column is numeric and then use a linear regression model to calculate the slope. \n",
            "\n",
            "Action: python_repl_ast\n",
            "Action Input: \n",
            "```python\n",
            "import pandas as pd\n",
            "from sklearn.linear_model import LinearRegression\n",
            "\n",
            "# Load the dataframe\n",
            "df = pd.read_csv('reform_AirPassengersDataset_DARTS_144.csv')\n",
            "\n",
            "# Check the data type of target column\n",
            "print(df['target'].dtypes)\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3mint64\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mThe target column is of type int64, which is numeric. So, we can proceed with the calculation of the slope. The slope of a linear regression model is calculated by fitting the model to the data points. The independent variable will be the index of the dataframe and the dependent variable will be the 'target' column. \n",
            "\n",
            "Action: python_repl_ast\n",
            "Action Input: \n",
            "```python\n",
            "# Initialize a linear regression model\n",
            "model = LinearRegression()\n",
            "\n",
            "# Reshape the index to use it as the independent variable\n",
            "X = df.index.values.reshape(-1, 1)\n",
            "\n",
            "# Fit the model to the data\n",
            "model.fit(X, df['target'])\n",
            "\n",
            "# Get the slope of the regression line\n",
            "slope = model.coef_[0]\n",
            "\n",
            "slope\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3m2.6571839080459774\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: The slope of the values in the target column of the dataframe df is approximately 2.657.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            ">>> Step executed:\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ==== slope calculation task ====\n",
        "state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the slope of values in the target column of df, then return the slope of target column only, no explanation.\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "# result = graph.invoke(state)\n",
        "# print(result[\"messages\"][-1].content)\n",
        "for update in graph.stream(state, stream_mode=\"updates\"):\n",
        "    print(\">>> Step executed:\")\n",
        "    if \"node\" in update:\n",
        "        print(f\"  Node: {update['node']}\")\n",
        "    if \"messages\" in update:\n",
        "        for msg in update[\"messages\"]:\n",
        "            print(f\"  Message: {getattr(msg, 'content', msg)}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmu_9UM2UF5f"
      },
      "source": [
        "results from previous two tasks are both correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-Mkil8tQUF5f",
        "outputId": "b212810d-2b4f-4bb1-8ea1-cfa83bcaa44e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Beginning AutoGluon training...\n",
            "AutoGluon will save models to '/content/drive/MyDrive/GE_Capstone/AI Agent Workflow/AutogluonModels/ag-20250415_232846'\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2.1b20250415\n",
            "Python Version:     3.11.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "GPU Count:          0\n",
            "Memory Avail:       10.84 GB / 12.67 GB (85.6%)\n",
            "Disk Space Avail:   63.56 GB / 107.72 GB (59.0%)\n",
            "===================================================\n",
            "Setting presets to: bolt_small\n",
            "\n",
            "Fitting with arguments:\n",
            "{'enable_ensemble': True,\n",
            " 'eval_metric': WQL,\n",
            " 'hyperparameters': {'Chronos': {'model_path': 'bolt_small'}},\n",
            " 'known_covariates_names': [],\n",
            " 'num_val_windows': 1,\n",
            " 'prediction_length': 24,\n",
            " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
            " 'random_seed': 123,\n",
            " 'refit_every_n_windows': 1,\n",
            " 'refit_full': False,\n",
            " 'skip_model_selection': True,\n",
            " 'target': 'target',\n",
            " 'verbosity': 2}\n",
            "\n",
            "Inferred time series frequency: 'MS'\n",
            "Provided train_data has 120 rows, 1 time series. Median time series length is 120 (min=120, max=120). \n",
            "\n",
            "Provided data contains following columns:\n",
            "\ttarget: 'target'\n",
            "\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "===================================================\n",
            "\n",
            "Starting training. Start time is 2025-04-15 23:28:50\n",
            "Models that will be trained: ['Chronos[bolt_small]']\n",
            "Training timeseries model Chronos[bolt_small]. \n",
            "\t11.41   s     = Training runtime\n",
            "Training complete. Models trained: ['Chronos[bolt_small]']\n",
            "Total runtime: 11.49 s\n",
            "Best model: Chronos[bolt_small]\n",
            "Model not specified in predict, will default to the model with the best validation score: Chronos[bolt_small]\n",
            "Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top model: Chronos[bolt_small], MAPE: 5.04%\n",
            "Forecast Preview:\n",
            " item_id  timestamp       mean\n",
            "       1 1960-03-01 414.699951\n",
            "       1 1960-04-01 419.955566\n",
            "       1 1960-05-01 428.213074\n",
            "       1 1960-06-01 483.538208\n",
            "       1 1960-07-01 525.270935\n",
            "       1 1960-08-01 521.030457\n",
            "       1 1960-09-01 468.151520\n",
            "       1 1960-10-01 409.785828\n",
            "       1 1960-11-01 384.249237\n",
            "       1 1960-12-01 402.730347\n"
          ]
        }
      ],
      "source": [
        "# ==== forecasting task ====\n",
        "initial_state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Please forecast the next 24 days using the file 'reform_AirPassengersDataset_DARTS_144.csv'.\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "result = graph.invoke(initial_state)\n",
        "print(result[\"messages\"][-1].content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qnLbJybdzDU",
        "outputId": "c4e012a6-939b-42f6-fe8b-df70a0aa533a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"R091: 2024-12-13\", \"R092: 2024-06-06\", \"R093: 2025-01-22\", \"R094: 2024-01-27\", \"R095: 2025-02-05\", \"R096: 2024-02-20\", \"R097: 2024-11-01\", \"R098: 2024-09-08\", \"R099: 2024-07-16\", \"R100: 2024-09-01\"]\n"
          ]
        }
      ],
      "source": [
        "# ==== Text Analysis task ====\n",
        "initial_state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Extract all instances where maintenance was performed from 'short.txt' based on the description column, do not include routine maintenance, give me the record ID and dates where maintenance was performed as list where each element is quoted.\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "result = graph.invoke(initial_state)\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Dzs7GOhhUF5g",
        "outputId": "cfb9adac-0098-4633-da51-b59ef5ad661a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Step executed:\n",
            "----------------------------------------\n",
            "[Separate] Sub-prompt: \"Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the slope of values in the target column of df and only return slope of target column, no explanation.\"\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To calculate the slope of the values in the target column, I need to perform a linear regression on the data. The slope of the regression line is the coefficient of the independent variable. In this case, the independent variable is the index of the dataframe, which can be considered as time. \n",
            "\n",
            "The slope can be calculated using numpy's polyfit function, which fits a polynomial of a specified degree to the data and returns the coefficients of the polynomial. For a linear regression, we'll use a polynomial of degree 1.\n",
            "\n",
            "Action: python_repl_ast\n",
            "Action Input: \n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "# Use np.polyfit to fit a degree 1 polynomial to the data. The first argument is the x values (the index), \n",
            "# and the second argument is the y values (the target column). It returns the coefficients of the polynomial, \n",
            "# where the first element is the slope and the second element is the y-intercept.\n",
            "slope, _ = np.polyfit(df.index, df['target'], 1)\n",
            "slope\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3m2.657183908045976\u001b[0m\u001b[32;1m\u001b[1;3mI have calculated the slope of the values in the target column. There are approximately 2.66 units increase in the target value for each unit increase in time.\n",
            "Final Answer: 2.657183908045976\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "[Separate] Sub-prompt: \"Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the 95% for target column of df. Only return a list of numbers that exceed the 95% value, no explanation.\"\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to load the file 'reform_AirPassengersDataset_DARTS_144.csv' and calculate the 95th percentile for the 'target' column in the dataframe `df`.\n",
            "Action: python_repl_ast\n",
            "Action Input: df['target'].quantile(0.95)\u001b[0m\u001b[36;1m\u001b[1;3m488.14999999999986\u001b[0m\u001b[32;1m\u001b[1;3mI have calculated the 95th percentile for the 'target' column in the dataframe `df`.\n",
            "Action: python_repl_ast\n",
            "Action Input: df[df['target'] > df['target'].quantile(0.95)]['target'].tolist()\u001b[0m\u001b[36;1m\u001b[1;3m[491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: [491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            ">>> Step executed:\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ==== threshold exceedance & slope calculation task in one prompt ====\n",
        "\n",
        "initial_state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Two prompts are in this sentence. Please separate and return them. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the slope of values in the target column of df and only return slope of target column, no explanation. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the 95% for target column of df. Only return a list of numbers that exceed the 95% value, no explanation.\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "# result = graph.invoke(initial_state)\n",
        "# print(result[\"messages\"][-1].content)\n",
        "for update in graph.stream(initial_state, stream_mode=\"updates\"):\n",
        "    print(\">>> Step executed:\")\n",
        "    if \"node\" in update:\n",
        "        print(f\"  Node: {update['node']}\")\n",
        "    if \"messages\" in update:\n",
        "        for msg in update[\"messages\"]:\n",
        "            print(f\"  Message: {getattr(msg, 'content', msg)}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbbagp2hUF5g",
        "outputId": "12ef03ed-312a-4702-ef5c-df0745b15383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Separate] Sub-prompt: 1. Extract all instances where maintenance was performed from file 'short.txt' based on the description column, do not include routine maintenance, return record ID and dates where maintenance was performed as list.\n",
            "[Separate] Sub-prompt: 2. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the slope of values in the target column of df and only return slope of target column, no explanation.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To calculate the slope of values in the target column, we need to perform a linear regression on the target values with respect to their corresponding indices. We can use the `numpy.polyfit` function to perform the linear regression. This function returns the coefficients of the polynomial that best fits the given data using the method of least squares. Since we are interested in a linear fit, we should use a degree of 1. The first coefficient returned by `numpy.polyfit` will be the slope of the line.\n",
            "\n",
            "Action: python_repl_ast\n",
            "Action Input: \n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "# Get the indices and target values as numpy arrays\n",
            "indices = df.index.to_numpy()\n",
            "target_values = df['target'].to_numpy()\n",
            "\n",
            "# Perform the linear regression to get the slope\n",
            "slope, _ = np.polyfit(indices, target_values, 1)\n",
            "slope\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3m2.657183908045976\u001b[0m\u001b[32;1m\u001b[1;3mThe slope of the line that best fits the target values in the dataframe `df` is approximately 2.657. This is the final answer.\n",
            "Final Answer: 2.657183908045976\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "[Separate] Sub-prompt: 3. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the 95% for target column of df, and only return a list of numbers that exceed the 95% value, no explanation.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to read the 'reform_AirPassengersDataset_DARTS_144.csv' file and calculate the 95th percentile for the target column in the df dataframe.\n",
            "Action: python_repl_ast\n",
            "Action Input: df['target'].quantile(0.95)\u001b[0m\u001b[36;1m\u001b[1;3m488.14999999999986\u001b[0m\u001b[32;1m\u001b[1;3mNow, I need to filter out the numbers in the 'target' column that exceed the 95th percentile value.\n",
            "Action: python_repl_ast\n",
            "Action Input: df[df['target'] > df['target'].quantile(0.95)]['target'].tolist()\u001b[0m\u001b[36;1m\u001b[1;3m[491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: [491, 505, 548, 559, 535, 622, 606, 508]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "[Separate] Sub-prompt: 4. Forecast the next 24 days using the file 'reform_AirPassengersDataset_DARTS_144.csv'.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Beginning AutoGluon training...\n",
            "AutoGluon will save models to '/content/drive/MyDrive/GE_Capstone/AI Agent Workflow/AutogluonModels/ag-20250415_233523'\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2.1b20250415\n",
            "Python Version:     3.11.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "GPU Count:          0\n",
            "Memory Avail:       10.44 GB / 12.67 GB (82.4%)\n",
            "Disk Space Avail:   63.56 GB / 107.72 GB (59.0%)\n",
            "===================================================\n",
            "Setting presets to: bolt_small\n",
            "\n",
            "Fitting with arguments:\n",
            "{'enable_ensemble': True,\n",
            " 'eval_metric': WQL,\n",
            " 'hyperparameters': {'Chronos': {'model_path': 'bolt_small'}},\n",
            " 'known_covariates_names': [],\n",
            " 'num_val_windows': 1,\n",
            " 'prediction_length': 24,\n",
            " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
            " 'random_seed': 123,\n",
            " 'refit_every_n_windows': 1,\n",
            " 'refit_full': False,\n",
            " 'skip_model_selection': True,\n",
            " 'target': 'target',\n",
            " 'verbosity': 2}\n",
            "\n",
            "Inferred time series frequency: 'MS'\n",
            "Provided train_data has 120 rows, 1 time series. Median time series length is 120 (min=120, max=120). \n",
            "\n",
            "Provided data contains following columns:\n",
            "\ttarget: 'target'\n",
            "\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "===================================================\n",
            "\n",
            "Starting training. Start time is 2025-04-15 23:35:23\n",
            "Models that will be trained: ['Chronos[bolt_small]']\n",
            "Training timeseries model Chronos[bolt_small]. \n",
            "\t0.01    s     = Training runtime\n",
            "Training complete. Models trained: ['Chronos[bolt_small]']\n",
            "Total runtime: 0.07 s\n",
            "Best model: Chronos[bolt_small]\n",
            "Model not specified in predict, will default to the model with the best validation score: Chronos[bolt_small]\n",
            "Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: 1. Extract all instances where maintenance was performed from file 'short.txt' based on the description column, do not include routine maintenance, return record ID and dates where maintenance was performed as list.\n",
            "Result: Below is the list of non‐routine maintenance records (showing Record ID and Date) extracted from file \"short.txt\":\n",
            "\n",
            "• R091 – 2024‑12‑13 (Gearbox realigned after detecting vibration anomalies)  \n",
            "• R092 – 2024‑06‑06 (Air filter replaced after detecting reduced airflow efficiency)  \n",
            "• R093 – 2025‑01‑22 (Faulty relay switch replaced after intermittent failures observed)  \n",
            "• R094 – 2024‑01‑27 (Pump seals replaced to resolve a detected minor leak)  \n",
            "• R095 – 2025‑02‑05 (System recalibrated following minor deviations in sensor readings)  \n",
            "• R096 – 2024‑02‑20 (Faulty relay switch replaced after intermittent failures observed)  \n",
            "• R097 – 2024‑11‑01 (Air filter replaced after detecting reduced airflow efficiency)  \n",
            "• R098 – 2024‑09‑08 (Technicians replaced a worn‑out belt to prevent further degradation)  \n",
            "• R099 – 2024‑07‑16 (System recalibrated following minor deviations in sensor readings)  \n",
            "• R100 – 2024‑09‑01 (Technicians replaced a worn‑out belt to prevent further degradation)  \n",
            "\n",
            "These entries represent maintenance activities involving component adjustments or replacements (i.e., corrective maintenance) rather than routine maintenance.\n",
            "\n",
            "Prompt: 2. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the slope of values in the target column of df and only return slope of target column, no explanation.\n",
            "Result: 2.657183908045976\n",
            "\n",
            "Prompt: 3. Use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the 95% for target column of df, and only return a list of numbers that exceed the 95% value, no explanation.\n",
            "Result: [491, 505, 548, 559, 535, 622, 606, 508]\n",
            "\n",
            "Prompt: 4. Forecast the next 24 days using the file 'reform_AirPassengersDataset_DARTS_144.csv'.\n",
            "Result: Top model: Chronos[bolt_small], MAPE: 5.04%\n",
            "Forecast Preview:\n",
            " item_id  timestamp       mean\n",
            "       1 1960-03-01 414.699951\n",
            "       1 1960-04-01 419.955566\n",
            "       1 1960-05-01 428.213074\n",
            "       1 1960-06-01 483.538208\n",
            "       1 1960-07-01 525.270935\n",
            "       1 1960-08-01 521.030457\n",
            "       1 1960-09-01 468.151520\n",
            "       1 1960-10-01 409.785828\n",
            "       1 1960-11-01 384.249237\n",
            "       1 1960-12-01 402.730347\n"
          ]
        }
      ],
      "source": [
        "# ==== text analysis & threshold exceedance & slope calculation & forecasting task in one prompt ====\n",
        "\n",
        "initial_state = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Four prompts are in this sentence. Please separate and return them. Firstly extract all instances where maintenance was performed from file 'short.txt' based on the description column, do not include routine maintenance, return record ID and dates where maintenance was performed as list. Secondly use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the slope of values in the target column of df and only return slope of target column, no explanation. Thirdly use the file 'reform_AirPassengersDataset_DARTS_144.csv' to calculate the 95% for target column of df, and only return a list of numbers that exceed the 95% value, no explanation. Finally forecast the next 24 days using the file 'reform_AirPassengersDataset_DARTS_144.csv'.\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "result = graph.invoke(initial_state)\n",
        "print(result[\"messages\"][-1].content)\n",
        "# for update in graph.stream(initial_state, stream_mode=\"updates\"):\n",
        "#     print(\">>> Step executed:\")\n",
        "#     if \"node\" in update:\n",
        "#         print(f\"  Node: {update['node']}\")\n",
        "#     if \"messages\" in update:\n",
        "#         for msg in update[\"messages\"]:\n",
        "#             print(f\"  Message: {getattr(msg, 'content', msg)}\")\n",
        "#     print(\"-\" * 40)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "hePSndWwhVmJ",
        "aLxppcEQhgoi",
        "MMc4_QdIxTIi"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1cb4ca320ad748c080fc230ec9b1f77d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce9993db03464544b95a8d1d37fd23d6",
            "placeholder": "​",
            "style": "IPY_MODEL_564d92ece0944ac1a252b80bc2be3d50",
            "value": "model.safetensors: 100%"
          }
        },
        "1ef1b50c7d814957b4cef01ee66fbb72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a8bacb16f3443119435b8c2e4bd5aad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cadc4f82c194d6a83fdee05c3276533": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fcc0f93e8464820bac4f0536c19e267": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "473a01fc09bd4367839b1d67abe4fb80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b4d0d7a40d046c19b3f0a9a708fd80e",
              "IPY_MODEL_55d2258afa1c41efa5e644abe2e92515",
              "IPY_MODEL_e765d47e43c94c128fe3fe09689f0760"
            ],
            "layout": "IPY_MODEL_3cadc4f82c194d6a83fdee05c3276533"
          }
        },
        "55d2258afa1c41efa5e644abe2e92515": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc33be7ba3d24a4faa61dc4643a47d95",
            "max": 1121,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ef1b50c7d814957b4cef01ee66fbb72",
            "value": 1121
          }
        },
        "564d92ece0944ac1a252b80bc2be3d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ee112ce9b2b4185bc11872df7d6f608": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d9a148eb4d7485d82ecba67a5a2d189": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dd71527c13c4111a88a2939f68b49ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b4d0d7a40d046c19b3f0a9a708fd80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce98bf65896143c6ac473a6a83e2f14e",
            "placeholder": "​",
            "style": "IPY_MODEL_7dd71527c13c4111a88a2939f68b49ec",
            "value": "config.json: 100%"
          }
        },
        "8c31254a2eab45af9b1b6e165140ae27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cb4ca320ad748c080fc230ec9b1f77d",
              "IPY_MODEL_a56df7d393a645dbb8d4b7f7a424bac8",
              "IPY_MODEL_a57b4775f928416689cc368b66e76c45"
            ],
            "layout": "IPY_MODEL_3a8bacb16f3443119435b8c2e4bd5aad"
          }
        },
        "a56df7d393a645dbb8d4b7f7a424bac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dde0805a77514e0bbd89bb36ca0d6271",
            "max": 190888824,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fcc0f93e8464820bac4f0536c19e267",
            "value": 190888824
          }
        },
        "a57b4775f928416689cc368b66e76c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ee112ce9b2b4185bc11872df7d6f608",
            "placeholder": "​",
            "style": "IPY_MODEL_eadf7d37d00a44b68f208afcb08dea16",
            "value": " 191M/191M [00:01&lt;00:00, 132MB/s]"
          }
        },
        "bc33be7ba3d24a4faa61dc4643a47d95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce98bf65896143c6ac473a6a83e2f14e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce9993db03464544b95a8d1d37fd23d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cee4d2b4e652465db07a53a693bf6c68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dde0805a77514e0bbd89bb36ca0d6271": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e765d47e43c94c128fe3fe09689f0760": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cee4d2b4e652465db07a53a693bf6c68",
            "placeholder": "​",
            "style": "IPY_MODEL_7d9a148eb4d7485d82ecba67a5a2d189",
            "value": " 1.12k/1.12k [00:00&lt;00:00, 49.9kB/s]"
          }
        },
        "eadf7d37d00a44b68f208afcb08dea16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
